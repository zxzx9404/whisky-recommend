{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743186f5",
   "metadata": {},
   "source": [
    "# Dataset fit_partial\n",
    "---\n",
    "- Dataset을 fit_partial 할 필요가 있다.\n",
    "- Dataset에는 기본적으로 rating.csv 부분은 바뀌지 않는다!\n",
    "\n",
    "최초 fit( \n",
    "    users : 전체 사용자 (가변) - 신규 사용자 들어올때마다 해당 index를 늘려줘야한다. => 아래로 붙여야할듯\n",
    "    items: 전체 위스키 ids (불변)\n",
    "    user_features : 사용 X\n",
    "    item_features : cost, flavor만 사용\n",
    "\n",
    "\n",
    "\n",
    "rating.csv  => interactions 변하지 않는다.\n",
    "하지만, \n",
    "db에서 가져오는 user-review-whisky 는 변할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f467ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSAFY\\anaconda3\\envs\\mini-project\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, auc_score, recall_at_k\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "## Normalization\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6b75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82084c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightFMResizable(LightFM):\n",
    "    \"\"\"A LightFM that resizes the model to accomodate new users,\n",
    "    items, and features\"\"\"\n",
    "\n",
    "    def fit_partial(\n",
    "        self,\n",
    "        interactions,\n",
    "        user_features=None,\n",
    "        item_features=None,\n",
    "        sample_weight=None,\n",
    "        epochs=1,\n",
    "        num_threads=1,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        try:\n",
    "            self._check_initialized()\n",
    "            self._resize(interactions, user_features, item_features)\n",
    "        except ValueError:\n",
    "            # This is the first call so just fit without resizing\n",
    "            pass\n",
    "\n",
    "        super().fit_partial(\n",
    "            interactions,\n",
    "            user_features,\n",
    "            item_features,\n",
    "            sample_weight,\n",
    "            epochs,\n",
    "            num_threads,\n",
    "            verbose,\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _resize(self, interactions, user_features=None, item_features=None):\n",
    "        \"\"\"Resizes the model to accommodate new users/items/features\"\"\"\n",
    "\n",
    "        no_components = self.no_components\n",
    "        no_user_features, no_item_features = interactions.shape  # default\n",
    "\n",
    "        if hasattr(user_features, \"shape\"):\n",
    "            no_user_features = user_features.shape[-1]\n",
    "        if hasattr(item_features, \"shape\"):\n",
    "            no_item_features = item_features.shape[-1]\n",
    "\n",
    "        if (\n",
    "            no_user_features == self.user_embeddings.shape[0]\n",
    "            and no_item_features == self.item_embeddings.shape[0]\n",
    "        ):\n",
    "            return self\n",
    "\n",
    "        new_model = clone(self)\n",
    "        new_model._initialize(no_components, no_item_features, no_user_features)\n",
    "\n",
    "        # update all attributes from self._check_initialized\n",
    "        for attr in (\n",
    "            \"item_embeddings\",\n",
    "            \"item_embedding_gradients\",\n",
    "            \"item_embedding_momentum\",\n",
    "            \"item_biases\",\n",
    "            \"item_bias_gradients\",\n",
    "            \"item_bias_momentum\",\n",
    "            \"user_embeddings\",\n",
    "            \"user_embedding_gradients\",\n",
    "            \"user_embedding_momentum\",\n",
    "            \"user_biases\",\n",
    "            \"user_bias_gradients\",\n",
    "            \"user_bias_momentum\",\n",
    "        ):\n",
    "            # extend attribute matrices with new rows/cols from\n",
    "            # freshly initialized model with right shape\n",
    "            old_array = getattr(self, attr)\n",
    "            old_slice = [slice(None, i) for i in old_array.shape]\n",
    "            new_array = getattr(new_model, attr)\n",
    "            new_array[tuple(old_slice)] = old_array\n",
    "            setattr(self, attr, new_array)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87837d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47381dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features = pd.read_csv(\"dataset/min_max_item_features.csv\", index_col=0, encoding=\"UTF-8\")\n",
    "# user_features = pd.read_csv(\"dataset/min_max_user_features.csv\", index_col=0, encoding=\"UTF-8\")\n",
    "# rating = pd.read_csv(\"dataset/rating.csv\", index_col=0, encoding=\"UTF-8\")\n",
    "# whisky = pd.read_csv(\"dataset/whisky.csv\", index_col=0, encoding=\"UTF-8\")\n",
    "\n",
    "rating = pd.read_csv(\"../dataset/rating.csv\", index_col=0, encoding=\"UTF-8\")\n",
    "whisky = pd.read_csv(\"../dataset/whisky.csv\", index_col=0, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bee8e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price_tier',\n",
       " 'smoky',\n",
       " 'peaty',\n",
       " 'spicy',\n",
       " 'herbal',\n",
       " 'oily',\n",
       " 'body',\n",
       " 'rich',\n",
       " 'sweet',\n",
       " 'salty',\n",
       " 'vanilla',\n",
       " 'tart',\n",
       " 'fruity',\n",
       " 'floral']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = whisky.columns.tolist()\n",
    "cols = [cols[8]] + cols[11:]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = whisky[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scalers\n",
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc90ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Min-Max normalization\n",
    "min_max_data = min_max_scaler.fit_transform(whisky[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb4ee96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_max_data = pd.DataFrame(min_max_data, columns=numeric_cols)\n",
    "min_max_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2006afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b873e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_df[cols[1:]] = min_max_scaler.fit_transform(item_df[cols[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
